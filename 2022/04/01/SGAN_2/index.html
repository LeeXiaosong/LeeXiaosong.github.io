<!DOCTYPE html><html lang="en_US" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>Social-GAN Open Source Code Analysis（二） | 宿松SuSong</title><meta name="keywords" content="Deep Learning,GAN"><meta name="author" content="Leon"><meta name="copyright" content="Leon"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="This blog is an open source code analysis of the paper by Fei-Fei Li et alSocial-GAN，Social GAN: Socially Acceptable Trajectories with Generative Adversarial Networks(CVPR,2018)持续更新中… 数据处理部分models.py在">
<meta property="og:type" content="article">
<meta property="og:title" content="Social-GAN Open Source Code Analysis（二）">
<meta property="og:url" content="http://example.com/2022/04/01/SGAN_2/index.html">
<meta property="og:site_name" content="宿松SuSong">
<meta property="og:description" content="This blog is an open source code analysis of the paper by Fei-Fei Li et alSocial-GAN，Social GAN: Socially Acceptable Trajectories with Generative Adversarial Networks(CVPR,2018)持续更新中… 数据处理部分models.py在">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://example.com/img/blogtopimg/SGAN.png">
<meta property="article:published_time" content="2022-03-31T16:00:00.000Z">
<meta property="article:modified_time" content="2022-03-31T16:00:00.000Z">
<meta property="article:author" content="Leon">
<meta property="article:tag" content="Deep Learning">
<meta property="article:tag" content="GAN">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/img/blogtopimg/SGAN.png"><link rel="shortcut icon" href="/img/star.png"><link rel="canonical" href="http://example.com/2022/04/01/SGAN_2/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: 'Just',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: true,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Social-GAN Open Source Code Analysis（二）',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2022-04-01 00:00:00'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" href="/css/background.css"><meta name="generator" content="Hexo 6.1.0"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/me.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data is-center"><div class="data-item"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">10</div></a></div><div class="data-item"><a href="/tags/"><div class="headline">Tags</div><div class="length-num">7</div></a></div><div class="data-item"><a href="/categories/"><div class="headline">Categories</div><div class="length-num">0</div></a></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('/img/blogtopimg/SGAN.png')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">宿松SuSong</a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Social-GAN Open Source Code Analysis（二）</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2022-03-31T16:00:00.000Z" title="Created 2022-04-01 00:00:00">2022-04-01</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2022-03-31T16:00:00.000Z" title="Updated 2022-04-01 00:00:00">2022-04-01</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="Social-GAN Open Source Code Analysis（二）"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post View:</span><span id="busuanzi_value_page_pv"></span></span><span class="post-meta-separator">|</span><span class="post-meta-commentcount"><i class="far fa-comments fa-fw post-meta-icon"></i><span class="post-meta-label">Comments:</span><a href="/2022/04/01/SGAN_2/#post-comment" itemprop="discussionUrl"><span class="valine-comment-count" data-xid="/2022/04/01/SGAN_2/" itemprop="commentCount"></span></a></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><p>This blog is an open source code analysis of the paper by Fei-Fei Li et al<br>Social-GAN，Social GAN: Socially Acceptable Trajectories with Generative Adversarial Networks(CVPR,2018)<br>持续更新中…</p>
<h1 id="数据处理部分"><a href="#数据处理部分" class="headerlink" title="数据处理部分"></a>数据处理部分</h1><h2 id="models-py"><a href="#models-py" class="headerlink" title="models.py"></a>models.py</h2><p>在第一篇代码解析的基础上，本文主要是有关网络模型models.py的介绍</p>
<p>关于torch.nn.Module，这里引用一下其他博主的介绍<a target="_blank" rel="noopener" href="https://blog.csdn.net/lovebasamessi/article/details/103222278">https://blog.csdn.net/lovebasamessi/article/details/103222278</a></p>
<blockquote>
<p>在pytorch中，nn.Module是所有神经网络单元的基类。pytorch在nn.Module中实现了__call__方法，而在__call__方法中调用了forward函数。__call__方法的主要作用是是类对象具有类似函数的功能，可以在类对象中进行传参，而__call__方法中又调用了forward函数。pytorch中的nn.Module类都包含了__init__方法与__call__方法。</p>
<ul>
<li>__init__:类的初始化函数，类似C++中的构造函数</li>
<li>__call__:使得类对象具有类似函数的功能</li>
</ul>
</blockquote>
<blockquote>
<p>举个例子，假设A是一个class,a是A的一个类对象，当我们执行a&#x3D;A(),这会调用__init__方法构造类的对象；而当我们执行a(),其会调用__call__方法，而在__call__方法内部又会调用forward函数，注意，这是通过类对象调用的，所以说使得类对象具有类似函数的功能。</p>
</blockquote>
<h3 id="make-mlp"><a href="#make-mlp" class="headerlink" title="make_mlp()"></a>make_mlp()</h3><p>make_mlp主要功能是构造多层的全连接网络，并且根据需求决定激活函数的类型，其参数dim_list是全连接网络各层维度的列表.get_noise函数主要是生成特定的噪声。<br>dim_list[a,b]则加一层Linear(a,b)<br>dim_list有时候是[a,b,c]则加两层Linear(a,b),Linear(b,c)</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"># 构造多层的全连接网络</span><br><span class="line"># 根据需求决定激活函数的类型</span><br><span class="line"># dim_list是全连接网络各层维度的列表</span><br><span class="line">def make_mlp(dim_list, activation=&#x27;relu&#x27;, batch_norm=True, dropout=0):</span><br><span class="line">    layers = []</span><br><span class="line">    for dim_in, dim_out in zip(dim_list[:-1], dim_list[1:]):</span><br><span class="line">        layers.append(nn.Linear(dim_in, dim_out))</span><br><span class="line">        if batch_norm:</span><br><span class="line">            layers.append(nn.BatchNorm1d(dim_out))</span><br><span class="line">        if activation == &#x27;relu&#x27;:            # 是否需要加relu</span><br><span class="line">            layers.append(nn.ReLU())</span><br><span class="line">        elif activation == &#x27;leakyrelu&#x27;:     # 是否需要加leakyrelu</span><br><span class="line">            layers.append(nn.LeakyReLU())</span><br><span class="line">        if dropout &gt; 0:</span><br><span class="line">            # 加入nn.Dropout层，元素置零的概率为p</span><br><span class="line">            layers.append(nn.Dropout(p=dropout))</span><br><span class="line">    return nn.Sequential(*layers)</span><br></pre></td></tr></table></figure>
<p>关于nn.Sequential(<em>layers)非关键字参数的用法<br><a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_43560675/article/details/108905632?utm_medium=distribute.pc_aggpage_search_result.none-task-blog-2~aggregatepage~first_rank_ecpm_v1~rank_v31_ecpm-1-108905632.pc_agg_new_rank&amp;utm_term=nn.Sequential(">https://blog.csdn.net/weixin_43560675/article/details/108905632?utm_medium=distribute.pc_aggpage_search_result.none-task-blog-2~aggregatepage~first_rank_ecpm_v1~rank_v31_ecpm-1-108905632.pc_agg_new_rank&amp;utm_term=nn.Sequential%28</a></em>layers%29+return&amp;spm&#x3D;1000.2123.3001.4430</p>
<h3 id="get-noise"><a href="#get-noise" class="headerlink" title="get_noise()"></a>get_noise()</h3><p>然后是根据shape大小生成特定噪声</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"># 生成特定的噪声</span><br><span class="line">def get_noise(shape, noise_type):</span><br><span class="line">    if noise_type == &#x27;gaussian&#x27;:   # 高斯分布</span><br><span class="line">        # return torch.randn(*shape).cuda()</span><br><span class="line">        return torch.randn(*shape).to(device)</span><br><span class="line">    elif noise_type == &#x27;uniform&#x27;:  # 均匀分布</span><br><span class="line">        # return torch.rand(*shape).sub_(0.5).mul_(2.0).cuda()</span><br><span class="line">        return torch.rand(*shape).sub_(0.5).mul_(2.0).to(device)</span><br><span class="line">        # sub_(0.5).mul_(2.0)减0.5在乘上2，生成[-1,1]的均匀分布</span><br><span class="line">    raise ValueError(&#x27;Unrecognized noise type &quot;%s&quot;&#x27; % noise_type)</span><br></pre></td></tr></table></figure>

<h3 id="Encoder-nn-Module"><a href="#Encoder-nn-Module" class="headerlink" title="Encoder(nn.Module)"></a>Encoder(nn.Module)</h3><p>在介绍Encoder部分之前，可能需要先明确Dataloader一次送入网络的数据格式<br>假设第i个sequence有$n_i$个有效序列，那么实际上一个Batch里面会有$\sum_{i&#x3D;1}^N n_i$个序列</p>
<blockquote>
<p>obs_traj: 观察到(已知)的序列，N(Batch_size)个sequence堆叠在一起并按帧的先后排列 [obs_len, $\sum_{i&#x3D;1}^N n_i$, 2]<br>pred_traj: 预测序列的真实值 [pred_len, $\sum_{i&#x3D;1}^N n_i$, 2]<br>obs_traj_rel: 观测到的轨迹的相对坐标 [obs_len, $\sum_{i&#x3D;1}^N n_i$, 2]<br>pred_traj_rel: 预测轨迹的真实轨迹的相对坐标 [pred_len, $\sum_{i&#x3D;1}^N n_i$, 2]<br>non_linear_ped:<br>loss_mask, seq_start_end: 每组sequence轨迹在_traj里的起始点</p>
</blockquote>
<p>输入的轨迹序列会被扩充到embedding_dim维，LSTM输入的特征向量也是embedding_dim维，隐藏向量的维数h_dim，<br>对于nn.LSTM，输入输出为<br><a target="_blank" rel="noopener" href="https://blog.csdn.net/tangweirensheng/article/details/120725172">https://blog.csdn.net/tangweirensheng/article/details/120725172</a></p>
<blockquote>
<p>Inputs: input, (h_0, c_0)<br>Outputs: output, (h_n, c_n)</p>
</blockquote>
<p>以训练句子为例子，假如每个词是100维的向量，每个句子含有24个单词，一次训练10个句子。那么batch_size&#x3D;10,seq&#x3D;24,input_size&#x3D;100。(seq指的是句子的长度，input_size作为一个x_{t}的输入) ，所以在设置LSTM网络的过程中input_size&#x3D;100。由于seq的长度是24，那么这个LSTM结构会循环24次最后输出预设的结果。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">class Encoder(nn.Module):</span><br><span class="line">    &quot;&quot;&quot;Encoder is part of both TrajectoryGenerator and</span><br><span class="line">    TrajectoryDiscriminator&quot;&quot;&quot;</span><br><span class="line">    def __init__(</span><br><span class="line">        self, embedding_dim=64, h_dim=64, mlp_dim=1024, num_layers=1,</span><br><span class="line">        dropout=0.0 # 不用dropout</span><br><span class="line">    ):</span><br><span class="line">        super(Encoder, self).__init__()</span><br><span class="line"></span><br><span class="line">        self.mlp_dim = 1024                 # 没有使用？</span><br><span class="line">        self.h_dim = h_dim                  # LSTM中隐层的维度</span><br><span class="line">        self.embedding_dim = embedding_dim  # 词向量维数（数据的特征维数）</span><br><span class="line">        self.num_layers = num_layers        # 堆叠LSTM的层数</span><br><span class="line"></span><br><span class="line">        self.encoder = nn.LSTM(</span><br><span class="line">            embedding_dim, h_dim, num_layers, dropout=dropout</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        self.spatial_embedding = nn.Linear(2, embedding_dim) # 全连接层</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>同时，在还定义了一个全连接层<br>后面通过调用spatial_embedding()</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">obs_traj_embedding = self.spatial_embedding(obs_traj.contiguous().view(-1, 2))</span><br><span class="line">obs_traj_embedding = obs_traj_embedding.view(</span><br><span class="line">    -1, batch, self.embedding_dim)</span><br></pre></td></tr></table></figure>
<p>将[***<em>len, $\sum</em>{i&#x3D;1}^N n_i$, 2]大小变成[obs_len, $\sum_{i&#x3D;1}^N n_i$, 64]</p>
<p>在LSTM网络中，隐藏层的初始状态$h_0,c_0$设置为全0</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">def init_hidden(self, batch):</span><br><span class="line">    return (</span><br><span class="line">        # GPU</span><br><span class="line">        # torch.zeros(self.num_layers, batch, self.h_dim).cuda(),</span><br><span class="line">        # torch.zeros(self.num_layers, batch, self.h_dim).cuda()</span><br><span class="line">        # CPU</span><br><span class="line">        torch.zeros(self.num_layers, batch, self.h_dim).to(device),</span><br><span class="line">        torch.zeros(self.num_layers, batch, self.h_dim).to(device)</span><br><span class="line">    )</span><br></pre></td></tr></table></figure>

<p>在class Encoder(nn.Module)里，还有一个就是forward()函数</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">def forward(self, obs_traj):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    Inputs:</span><br><span class="line">    - obs_traj: Tensor of shape (obs_len, batch, 2)</span><br><span class="line">    Output:</span><br><span class="line">    - final_h: Tensor of shape (self.num_layers, batch, self.h_dim)</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    # Encode observed Trajectory</span><br><span class="line">    batch = obs_traj.size(1)</span><br><span class="line">    # obs_traj_embedding = self.spatial_embedding(obs_traj.view(-1, 2))</span><br><span class="line">    obs_traj_embedding = self.spatial_embedding(obs_traj.contiguous().view(-1, 2))</span><br><span class="line">    # view(-1, 2)把数据变成两列</span><br><span class="line">    obs_traj_embedding = obs_traj_embedding.view(</span><br><span class="line">        -1, batch, self.embedding_dim)</span><br><span class="line">    state_tuple = self.init_hidden(batch)</span><br><span class="line">    output, state = self.encoder(obs_traj_embedding, state_tuple)</span><br><span class="line">    # 隐藏状态h_t记为final_h, state = h_t,c_t</span><br><span class="line">    final_h = state[0]</span><br><span class="line">    return final_h</span><br></pre></td></tr></table></figure>
<p>总的来说，Encoder的作用就是就是把一个batch的数据[obs_len, $\sum_{i&#x3D;1}^N n_i$, 2]编码成对应的$h_f$[num_layer, $\sum_{i&#x3D;1}^N n_i$, 64]</p>
<p>为了便于理解，这里引用了大佬制作的图片<br><img src="/SGAN_2/SGAN_2_2022-04-01-11-46-25.png"><br>当然也有博主在这里提到一个问题就是</p>
<blockquote>
<p>“另外，源代码中有一个地方与论文中描述的不太一样，论文中在2*16的全连接层之后接了Relu激活函数，但是在源代码中并没有体现。”</p>
</blockquote>
<h3 id="PoolHiddenNet-nn-Module"><a href="#PoolHiddenNet-nn-Module" class="headerlink" title="PoolHiddenNet(nn.Module)"></a>PoolHiddenNet(nn.Module)</h3><p>在分析class Decoder()之前先来看池化层class PoolHiddenNet<br>其__init__方法中分别定义了2*embedding_dim(64)以及mlp_pre_dim(128)*512*bottleneck_dim(1024)两个全连接层，并且后面这个全连接层带relu激活函数。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">def __init__(</span><br><span class="line">    self, embedding_dim=64, h_dim=64, mlp_dim=1024, bottleneck_dim=1024,</span><br><span class="line">    activation=&#x27;relu&#x27;, batch_norm=True, dropout=0.0</span><br><span class="line">):</span><br><span class="line">    super(PoolHiddenNet, self).__init__()</span><br><span class="line"></span><br><span class="line">    self.mlp_dim = 1024</span><br><span class="line">    self.h_dim = h_dim</span><br><span class="line">    self.bottleneck_dim = bottleneck_dim</span><br><span class="line">    self.embedding_dim = embedding_dim</span><br><span class="line"></span><br><span class="line">    mlp_pre_dim = embedding_dim + h_dim</span><br><span class="line">    mlp_pre_pool_dims = [mlp_pre_dim, 512, bottleneck_dim]</span><br><span class="line"></span><br><span class="line">    # 全连接层</span><br><span class="line">    self.spatial_embedding = nn.Linear(2, embedding_dim)</span><br><span class="line"></span><br><span class="line">    # MLP，调用定义的make_mlp()构造nn.linear()</span><br><span class="line">    self.mlp_pre_pool = make_mlp(</span><br><span class="line">        mlp_pre_pool_dims,</span><br><span class="line">        activation=activation,</span><br><span class="line">        batch_norm=batch_norm,</span><br><span class="line">        dropout=dropout)</span><br></pre></td></tr></table></figure>

<p>在PoolHiddenNet类中，作者还定义了一个repeat()函数，用于复制序列。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">def repeat(self, tensor, num_reps):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    Inputs:</span><br><span class="line">    -tensor: 2D tensor of any shape</span><br><span class="line">    -num_reps: Number of times to repeat each row</span><br><span class="line">    Outpus:</span><br><span class="line">    -repeat_tensor: Repeat each row such that: R1, R1, R2, R2</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    col_len = tensor.size(1)  # 返回张量的行数</span><br><span class="line">    tensor = tensor.unsqueeze(dim=1).repeat(1, num_reps, 1)</span><br><span class="line">    # unsqueeze(dim)在dim位置增加一维 （2）-&gt;unsqueeze(dim=1)-&gt;(2,1)</span><br><span class="line">    # repeat(a, b, c) 复制a个，b行，c个原向量</span><br><span class="line">    tensor = tensor.view(-1, col_len) # 变成col_len列数据</span><br><span class="line">    return tensor</span><br></pre></td></tr></table></figure>


<p>forward()函数的第一个参数h_states就是Encoder的输出final_h，其维度为[num_layers, batch, hidden_size]，在程序中即[1, batch, 32]，batch即batch_size个sequence序列中的总人数$\sum_{i&#x3D;1}^N n_i$，每一批数据其个数一般是不相等的。<br>在seq_collate()中，</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">seq_start_end = [[start, end]</span><br><span class="line">                     for start, end in zip(cum_start_idx, cum_start_idx[1:])]</span><br><span class="line"># seq_start_end = [[0, 2], [2, 5], [5, 7], [7, 11]...]</span><br></pre></td></tr></table></figure>
<p>seq_start_end是一个batch数据中，每个sequence包含的有效轨迹的起始序号<br>假设第i个sequcence中的有效轨迹有$n_i$条</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">def forward(self, h_states, seq_start_end, end_pos):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    Inputs:</span><br><span class="line">    - h_states: Tensor of shape (num_layers, batch, h_dim)</span><br><span class="line">    - seq_start_end: A list of tuples which delimit sequences within batch</span><br><span class="line">    - end_pos: Tensor of shape (batch, 2)</span><br><span class="line">    Output:</span><br><span class="line">    - pool_h: Tensor of shape (batch, bottleneck_dim)</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    pool_h = []</span><br><span class="line">    # 按照每个sequcence循环</span><br><span class="line">    for _, (start, end) in enumerate(seq_start_end):</span><br><span class="line">        start = start.item()</span><br><span class="line">        end = end.item()</span><br><span class="line">        num_ped = end - start</span><br><span class="line">        # 抽取第i个sequcence中的轨迹对应的h_f</span><br><span class="line">        curr_hidden = h_states.view(-1, self.h_dim)[start:end]</span><br><span class="line">        curr_end_pos = end_pos[start:end]</span><br><span class="line"></span><br><span class="line">        # Repeat -&gt; H1, H2, H3, H1, H2, H3, H1, H2, H3</span><br><span class="line">        curr_hidden_1 = curr_hidden.repeat(num_ped, 1)</span><br><span class="line">        # Repeat position -&gt; P1, P2, P3, P1, P2, P3, P1, P2, P3</span><br><span class="line">        curr_end_pos_1 = curr_end_pos.repeat(num_ped, 1)</span><br><span class="line">        # Repeat position -&gt; P1, P1, P1, P2, P2, P2, P3, P3, P3</span><br><span class="line">        curr_end_pos_2 = self.repeat(curr_end_pos, num_ped)</span><br><span class="line">        curr_rel_pos = curr_end_pos_1 - curr_end_pos_2</span><br><span class="line"></span><br><span class="line">        # 将[batch*batch,2]数据输入至2*64的全连接层得到[batch*batch,64]的curr_rel_embedding</span><br><span class="line">        curr_rel_embedding = self.spatial_embedding(curr_rel_pos)</span><br><span class="line">        # 对curr_rel_embedding, curr_hidden_1做拼接</span><br><span class="line">        mlp_h_input = torch.cat([curr_rel_embedding, curr_hidden_1], dim=1)</span><br><span class="line"></span><br><span class="line">        # 将拼接的数据送入由二个全连接层构造的MLP, 得到[N*N, 1024]</span><br><span class="line">        curr_pool_h = self.mlp_pre_pool(mlp_h_input) </span><br><span class="line"></span><br><span class="line">        # 做maxpool操作</span><br><span class="line">        curr_pool_h = curr_pool_h.view(num_ped, num_ped, -1).max(1)[0]</span><br><span class="line">        </span><br><span class="line">        # 对这批数据所有序列都进行相应的处理，新的pool_h为[batch,8]，每一行对应一个人</span><br><span class="line">        pool_h.append(curr_pool_h)</span><br><span class="line">    pool_h = torch.cat(pool_h, dim=0)</span><br><span class="line">    return pool_h</span><br></pre></td></tr></table></figure>


<p>forward函数内部对DataLoader加载的batch_size个sequence序列逐次处理。在对每一个序列进行处理时，对每一个序列处理的示意图如下图所示。<br><img src="/SGAN_2/SGAN_2_2022-04-01-17-37-57.png"><br>最终得到每个人特征张量Pi，该向量包含了他自己的轨迹信息和同一序列下其他人轨迹的相对信息<br><img src="/SGAN_2/SGAN_2_2022-04-01-17-38-53.png"></p>
<h3 id="Decoder-nn-Module"><a href="#Decoder-nn-Module" class="headerlink" title="Decoder(nn.Module)"></a>Decoder(nn.Module)</h3><p>然后就是class Decoder()部分，它的__init__方法中定义了一个LSTM网络结构，一个2*16的全连接层，一个32*2的全连接层，并且根据是否每生成一次预测数据都池化一次又定义了池化层与全连接层。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">class Decoder(nn.Module):</span><br><span class="line">    &quot;&quot;&quot;Decoder is part of TrajectoryGenerator&quot;&quot;&quot;</span><br><span class="line">    def __init__(</span><br><span class="line">        self, seq_len, embedding_dim=64, h_dim=128, mlp_dim=1024, num_layers=1,</span><br><span class="line">        pool_every_timestep=True, dropout=0.0, bottleneck_dim=1024,</span><br><span class="line">        activation=&#x27;relu&#x27;, batch_norm=True, pooling_type=&#x27;pool_net&#x27;,</span><br><span class="line">        neighborhood_size=2.0, grid_size=8</span><br><span class="line">    ):</span><br><span class="line">        super(Decoder, self).__init__()</span><br><span class="line"></span><br><span class="line">        self.seq_len = seq_len</span><br><span class="line">        self.mlp_dim = mlp_dim</span><br><span class="line">        self.h_dim = h_dim</span><br><span class="line">        self.embedding_dim = embedding_dim</span><br><span class="line">        self.pool_every_timestep = pool_every_timestep</span><br><span class="line"></span><br><span class="line">        self.decoder = nn.LSTM(</span><br><span class="line">            embedding_dim, h_dim, num_layers, dropout=dropout</span><br><span class="line">        )</span><br></pre></td></tr></table></figure>
<p>其中有几个参数</p>
<blockquote>
<p>pool_every_timestep &#x3D; True # 每一次预测后是否根据新的坐标重新池化<br>neighborhood_size &#x3D; 2.0 #没用到<br>grid_size &#x3D; 8 #没用到</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">if pool_every_timestep:</span><br><span class="line">    if pooling_type == &#x27;pool_net&#x27;:</span><br><span class="line">        self.pool_net = PoolHiddenNet(</span><br><span class="line">            embedding_dim=self.embedding_dim,</span><br><span class="line">            h_dim=self.h_dim,</span><br><span class="line">            mlp_dim=mlp_dim,</span><br><span class="line">            bottleneck_dim=bottleneck_dim,</span><br><span class="line">            activation=activation,</span><br><span class="line">            batch_norm=batch_norm,</span><br><span class="line">            dropout=dropout</span><br><span class="line">        )</span><br><span class="line">    # elif pooling_type == &#x27;spool&#x27;:</span><br><span class="line">    # ...</span><br><span class="line"></span><br><span class="line">    mlp_dims = [h_dim + bottleneck_dim, mlp_dim, h_dim]</span><br><span class="line">    self.mlp = make_mlp(</span><br><span class="line">        mlp_dims,</span><br><span class="line">        activation=activation,</span><br><span class="line">        batch_norm=batch_norm,</span><br><span class="line">        dropout=dropout</span><br><span class="line">    )</span><br><span class="line">self.spatial_embedding = nn.Linear(2, embedding_dim)</span><br><span class="line">self.hidden2pos = nn.Linear(h_dim, 2)</span><br></pre></td></tr></table></figure>

<p>mlp在Decoder中主要用在pool_h和final_encoder_h拼接之后，然后输出h_dim(64)维的向量，所以其输入维度是h_dim(64)和bottleneck_dim(64)之和即128维。<br>spatial_embedding在这里和Encoder定义的函数作用相似。<br>hidden2pos则是把最后输出的hidden向量变成位置坐标。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">def forward(self, last_pos, last_pos_rel, state_tuple, seq_start_end):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    Inputs:</span><br><span class="line">    - last_pos: Tensor of shape (batch, 2)</span><br><span class="line">    - last_pos_rel: Tensor of shape (batch, 2)</span><br><span class="line">    - state_tuple: (hh, ch) each tensor of shape (num_layers, batch, h_dim)</span><br><span class="line">    - seq_start_end: A list of tuples which delimit sequences within batch</span><br><span class="line">    Output:</span><br><span class="line">    - pred_traj: tensor of shape (self.seq_len, batch, 2)</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    batch = last_pos.size(0)</span><br><span class="line">    pred_traj_fake_rel = []</span><br><span class="line">    decoder_input = self.spatial_embedding(last_pos_rel)</span><br><span class="line">    decoder_input = decoder_input.view(1, batch, self.embedding_dim)</span><br><span class="line"></span><br><span class="line">    for _ in range(self.seq_len):</span><br><span class="line">        # seq_len = obs_len + pred_len</span><br><span class="line">        # 为什么是seq_len而不是pred_len</span><br><span class="line">        output, state_tuple = self.decoder(decoder_input, state_tuple)</span><br><span class="line">        # decoder生成的相对上一帧的坐标(预测值)</span><br><span class="line">        rel_pos = self.hidden2pos(output.view(-1, self.h_dim))</span><br><span class="line">        curr_pos = rel_pos + last_pos # 得到绝对坐标</span><br><span class="line"></span><br><span class="line">        if self.pool_every_timestep:</span><br><span class="line">        # 预测出一帧的坐标变化后是否要重新池化</span><br><span class="line">            decoder_h = state_tuple[0]</span><br><span class="line">            pool_h = self.pool_net(decoder_h, seq_start_end, curr_pos)</span><br><span class="line">            decoder_h = torch.cat(</span><br><span class="line">                [decoder_h.view(-1, self.h_dim), pool_h], dim=1)</span><br><span class="line">            decoder_h = self.mlp(decoder_h)</span><br><span class="line">            decoder_h = torch.unsqueeze(decoder_h, 0)</span><br><span class="line">            state_tuple = (decoder_h, state_tuple[1])</span><br><span class="line"></span><br><span class="line">        embedding_input = rel_pos</span><br><span class="line"></span><br><span class="line">        decoder_input = self.spatial_embedding(embedding_input)</span><br><span class="line">        decoder_input = decoder_input.view(1, batch, self.embedding_dim)</span><br><span class="line">        pred_traj_fake_rel.append(rel_pos.view(batch, -1))</span><br><span class="line">        last_pos = curr_pos</span><br><span class="line"></span><br><span class="line">    pred_traj_fake_rel = torch.stack(pred_traj_fake_rel, dim=0)</span><br><span class="line">    # 预测的是相对坐标</span><br><span class="line">    return pred_traj_fake_rel, state_tuple[0]</span><br></pre></td></tr></table></figure>
<p>在if self.pool_every_timestep: 如果不重新池化，那么decoder里输入的state_tuple(hh, ch)始终是根据前8个已知的轨迹和第8帧的和其他人的位置相对信息得到；如果要池化，那么就通过self.pool_net把上一次的hh和最新的预测坐标送入PoolHiddenNet得到新的pool_h。<br>大致流程如下：<br><img src="/SGAN_2/SGAN_2_2022-04-01-22-30-56.png"></p>
<p>这里有个疑问就是</p>
<blockquote>
<p>   for _ in range(self.seq_len):<br>        # seq_len &#x3D; obs_len + pred_len<br>        # 为什么是seq_len而不是pred_len</p>
</blockquote>
<h3 id="TrajectoryGenerator-nn-Module"><a href="#TrajectoryGenerator-nn-Module" class="headerlink" title="TrajectoryGenerator(nn.Module)"></a>TrajectoryGenerator(nn.Module)</h3><p>接下来就是关于轨迹生成器的定义，__init__里面前面一大段就是参数的初始化</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">class TrajectoryGenerator(nn.Module):</span><br><span class="line">    def __init__(</span><br><span class="line">        self, obs_len, pred_len, embedding_dim=64, encoder_h_dim=64,</span><br><span class="line">        decoder_h_dim=128, mlp_dim=1024, num_layers=1, noise_dim=(0, ),</span><br><span class="line">        noise_type=&#x27;gaussian&#x27;, noise_mix_type=&#x27;ped&#x27;, pooling_type=None,</span><br><span class="line">        pool_every_timestep=True, dropout=0.0, bottleneck_dim=1024,</span><br><span class="line">        activation=&#x27;relu&#x27;, batch_norm=True, neighborhood_size=2.0, grid_size=8</span><br><span class="line">    ):</span><br><span class="line">        super(TrajectoryGenerator, self).__init__()</span><br><span class="line"></span><br><span class="line">        if pooling_type and pooling_type.lower() == &#x27;none&#x27;:</span><br><span class="line">            pooling_type = None</span><br><span class="line"></span><br><span class="line">        self.obs_len = obs_len</span><br><span class="line">        self.pred_len = pred_len</span><br><span class="line">        self.mlp_dim = mlp_dim</span><br><span class="line">        self.encoder_h_dim = encoder_h_dim</span><br><span class="line">        self.decoder_h_dim = decoder_h_dim</span><br><span class="line">        self.embedding_dim = embedding_dim</span><br><span class="line">        self.noise_dim = noise_dim</span><br><span class="line">        self.num_layers = num_layers</span><br><span class="line">        self.noise_type = noise_type</span><br><span class="line">        self.noise_mix_type = noise_mix_type</span><br><span class="line">        self.pooling_type = pooling_type</span><br><span class="line">        self.noise_first_dim = 0</span><br><span class="line">        self.pool_every_timestep = pool_every_timestep</span><br><span class="line">        self.bottleneck_dim = 1024</span><br></pre></td></tr></table></figure>

<p>然后就是encoder和decode的一些参数初始化，在这里定义了pool_net函数，作用是根据输入参数调用PoolHiddenNet对LSTM得到的最后输出的隐藏层向量做池化操作。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">self.encoder = Encoder(</span><br><span class="line">    embedding_dim=embedding_dim,</span><br><span class="line">    h_dim=encoder_h_dim,</span><br><span class="line">    mlp_dim=mlp_dim,</span><br><span class="line">    num_layers=num_layers,</span><br><span class="line">    dropout=dropout</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">self.decoder = Decoder(</span><br><span class="line">    pred_len,</span><br><span class="line">    embedding_dim=embedding_dim,</span><br><span class="line">    h_dim=decoder_h_dim,</span><br><span class="line">    mlp_dim=mlp_dim,</span><br><span class="line">    num_layers=num_layers,</span><br><span class="line">    pool_every_timestep=pool_every_timestep,</span><br><span class="line">    dropout=dropout,</span><br><span class="line">    bottleneck_dim=bottleneck_dim,</span><br><span class="line">    activation=activation,</span><br><span class="line">    batch_norm=batch_norm,</span><br><span class="line">    pooling_type=pooling_type,</span><br><span class="line">    grid_size=grid_size,</span><br><span class="line">    neighborhood_size=neighborhood_size</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">if pooling_type == &#x27;pool_net&#x27;:</span><br><span class="line">    self.pool_net = PoolHiddenNet(</span><br><span class="line">        embedding_dim=self.embedding_dim,</span><br><span class="line">        h_dim=encoder_h_dim,</span><br><span class="line">        mlp_dim=mlp_dim,</span><br><span class="line">        bottleneck_dim=bottleneck_dim,</span><br><span class="line">        activation=activation,</span><br><span class="line">        batch_norm=batch_norm</span><br><span class="line">    )</span><br></pre></td></tr></table></figure>

<p>再来看forward()函数的内容，前面作者的注释很详细，对于Dataloader传来的数据大小给出了很详细的说明</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">def forward(self, obs_traj, obs_traj_rel, seq_start_end, user_noise=None):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    Inputs:</span><br><span class="line">    - obs_traj: Tensor of shape (obs_len, batch, 2)</span><br><span class="line">    - obs_traj_rel: Tensor of shape (obs_len, batch, 2)</span><br><span class="line">    - seq_start_end: A list of tuples which delimit sequences within batch.</span><br><span class="line">    - user_noise: Generally used for inference when you want to see</span><br><span class="line">    relation between different types of noise and outputs.</span><br><span class="line">    Output:</span><br><span class="line">    - pred_traj_rel: Tensor of shape (self.pred_len, batch, 2)</span><br><span class="line">    &quot;&quot;&quot;</span><br></pre></td></tr></table></figure>
<p>然后就是对传入的数据依次处理</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">batch = obs_traj_rel.size(1)</span><br><span class="line"># Encode seq</span><br><span class="line">final_encoder_h = self.encoder(obs_traj_rel)</span><br><span class="line"># 对轨迹做encoder得到最后的隐藏状态</span><br><span class="line"># Pool States</span><br><span class="line">if self.pooling_type:</span><br><span class="line">    # 如果加入池化层</span><br><span class="line">    end_pos = obs_traj[-1, :, :]</span><br><span class="line">    pool_h = self.pool_net(final_encoder_h, seq_start_end, end_pos)</span><br><span class="line">    # Construct input hidden states for decoder</span><br><span class="line">    mlp_decoder_context_input = torch.cat(</span><br><span class="line">        [final_encoder_h.view(-1, self.encoder_h_dim), pool_h], dim=1)</span><br><span class="line">else:</span><br><span class="line">    mlp_decoder_context_input = final_encoder_h.view(</span><br><span class="line">        -1, self.encoder_h_dim)</span><br></pre></td></tr></table></figure>
<p>在这里：</p>
<ul>
<li>如果加入了池化层则将上一步encoder得到的最终隐藏层向量final_encoder_h等数据送入池化层，得到每个人的特征向量pool_h，并将final_encoder_h与pool_h进行拼接，得到mlp_decoder_context_input。</li>
<li>没有池化层，直接将上一步得到的final_encoder_h经过维度变换作为mlp_decoder_context_input<br>对应的就是原文中图中的箭头部分<br><img src="/SGAN_2/SGAN_2_2022-04-03-14-09-53.png"></li>
</ul>
<p>在加入噪声前，也需要对得到的数据进行维度处理，保证输入的维度和add_noise()定义的_input格式大小(_, decoder_h_dim(128) - noise_first_dim)一致。如果上面做了拼接，那么mlp_decoder_context_input中每一行的长度就是h_dim(64)+bottleneck_dim(1024)&#x3D;1088维，但是add_noise()里定义的_input长度是decoder_h_dim - noise_first_dim，所以需要加一个MLP，如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"># 增加全连接层</span><br><span class="line">if self.mlp_decoder_needed():</span><br><span class="line">    mlp_decoder_context_dims = [</span><br><span class="line">        input_dim, mlp_dim, decoder_h_dim - self.noise_first_dim</span><br><span class="line">    ]</span><br><span class="line"></span><br><span class="line">    self.mlp_decoder_context = make_mlp(</span><br><span class="line">        mlp_decoder_context_dims,</span><br><span class="line">        activation=activation,</span><br><span class="line">        batch_norm=batch_norm,</span><br><span class="line">        dropout=dropout</span><br><span class="line">    )</span><br></pre></td></tr></table></figure>
<p>保证输入的长度decoder_h_dim - self.noise_first_dim，即在后面加上噪声后长度大小满足decoder_h的要求(decoder_h_dim)。<br>附上大佬的图片<br><img src="/SGAN_2/SGAN_2_2022-04-03-15-49-12.png"></p>
<p>关于添加噪声的处理，<br>除了第一次添加噪声z之外，后续每一步的池化都不需要再追加噪声z了。所以，每一帧的预测中，会根据pool_every_timestep(True&#x2F;False)判断每次预测后是否重新池化，但不会再追加噪声z。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">def add_noise(self, _input, seq_start_end, user_noise=None):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    Inputs:</span><br><span class="line">    - _input: Tensor of shape (_, decoder_h_dim - noise_first_dim)</span><br><span class="line">    - seq_start_end: A list of tuples which delimit sequences within batch.</span><br><span class="line">    - user_noise: Generally used for inference when you want to see</span><br><span class="line">    relation between different types of noise and outputs.</span><br><span class="line">    Outputs:</span><br><span class="line">    - decoder_h: Tensor of shape (_, decoder_h_dim)</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    if not self.noise_dim:</span><br><span class="line">        return _input</span><br><span class="line"></span><br><span class="line">    # 全局噪声还是非全局噪声</span><br><span class="line">    # 如果是全局噪声，则每个人的噪声都一样，否则每个人的噪声都不一样。</span><br><span class="line">    if self.noise_mix_type == &#x27;global&#x27;:</span><br><span class="line">        noise_shape = (seq_start_end.size(0), ) + self.noise_dim</span><br><span class="line">    else:</span><br><span class="line">        noise_shape = (_input.size(0), ) + self.noise_dim</span><br><span class="line"></span><br><span class="line">    if user_noise is not None:</span><br><span class="line">        z_decoder = user_noise</span><br><span class="line">    else:</span><br><span class="line">        z_decoder = get_noise(noise_shape, self.noise_type)</span><br><span class="line"></span><br><span class="line">    if self.noise_mix_type == &#x27;global&#x27;:</span><br><span class="line">        _list = []</span><br><span class="line">        for idx, (start, end) in enumerate(seq_start_end):</span><br><span class="line">            start = start.item()</span><br><span class="line">            end = end.item()</span><br><span class="line">            _vec = z_decoder[idx].view(1, -1)</span><br><span class="line">            _to_cat = _vec.repeat(end - start, 1)</span><br><span class="line">            _list.append(torch.cat([_input[start:end], _to_cat], dim=1))</span><br><span class="line">        decoder_h = torch.cat(_list, dim=0)</span><br><span class="line">        return decoder_h</span><br><span class="line"></span><br><span class="line">    decoder_h = torch.cat([_input, z_decoder], dim=1)</span><br><span class="line"></span><br><span class="line">    return decoder_h</span><br></pre></td></tr></table></figure>
<p>所以在这里，经过Pooling Module模块后，三个类型的长方形和所代表的数据便一一对应上了。<br><img src="/SGAN_2/SGAN_2_2022-04-03-14-09-53.png"></p>
<p>回到forward()这里，经过全连接层之后，将得到的noise_input与一个噪声z进行合并，得到decoder_h</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">decoder_h = self.add_noise(</span><br><span class="line">    noise_input, seq_start_end, user_noise=user_noise)</span><br><span class="line">decoder_h = torch.unsqueeze(decoder_h, 0)</span><br><span class="line"># LSTM网络定义的num_layers=1，所以用unsqueeze加了一个维度？</span><br><span class="line"></span><br><span class="line"># decoder_c的初始化，这里我把.cuda()改成了.to(device)</span><br><span class="line">decoder_c = torch.zeros(</span><br><span class="line">    self.num_layers, batch, self.decoder_h_dim</span><br><span class="line">).to(device)</span><br></pre></td></tr></table></figure>

<p>最后就是把轨迹数据丢到decoder中，得到后12帧的预测轨迹pred_traj_fake_rel，大小为(self.pred_len, batch, 2)。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">state_tuple = (decoder_h, decoder_c)</span><br><span class="line">last_pos = obs_traj[-1]</span><br><span class="line">last_pos_rel = obs_traj_rel[-1]</span><br><span class="line"></span><br><span class="line"># Predict Trajectory</span><br><span class="line">decoder_out = self.decoder(</span><br><span class="line">    last_pos,</span><br><span class="line">    last_pos_rel,</span><br><span class="line">    state_tuple,</span><br><span class="line">    seq_start_end,</span><br><span class="line">)</span><br><span class="line">pred_traj_fake_rel, final_decoder_h = decoder_out</span><br><span class="line"></span><br><span class="line">return pred_traj_fake_rel</span><br></pre></td></tr></table></figure>


<p>接下来，就是最后一个类TrajectoryDiscriminator了，这个类比较简单。其主要就是对轨迹进行打分，以判断轨迹是真实的轨迹还是预测的轨迹。其主要是copy了一份上文encoder部分的网络，然后得到final_h，另外又搭建了一个全连接层，该全连接层输出网络生成的分数。<br>另外这个类里面有一个d_type选项，其默认是local，如果是local的话，其会直接把final_h做维度变化作为全连接层的输入。如果是global的话，final_h需要先作为一个池化层的输入，经过池化以后再输入至全连接层生成得分。程序默认d_type为local，也就是独立的处理每一条轨迹，为每一条轨迹打分。global的话我猜大致是直接为这一批轨迹打分，这一批轨迹的分数都是一样的，即他们要么全被当做真实轨迹要么全被当做预测轨迹。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line">class TrajectoryDiscriminator(nn.Module):</span><br><span class="line">    def __init__(</span><br><span class="line">        self, obs_len, pred_len, embedding_dim=64, h_dim=64, mlp_dim=1024,</span><br><span class="line">        num_layers=1, activation=&#x27;relu&#x27;, batch_norm=True, dropout=0.0,</span><br><span class="line">        d_type=&#x27;local&#x27;</span><br><span class="line">    ):</span><br><span class="line">        super(TrajectoryDiscriminator, self).__init__()</span><br><span class="line"></span><br><span class="line">        self.obs_len = obs_len</span><br><span class="line">        self.pred_len = pred_len</span><br><span class="line">        self.seq_len = obs_len + pred_len</span><br><span class="line">        self.mlp_dim = mlp_dim</span><br><span class="line">        self.h_dim = h_dim</span><br><span class="line">        self.d_type = d_type</span><br><span class="line"></span><br><span class="line">        self.encoder = Encoder(</span><br><span class="line">            embedding_dim=embedding_dim,</span><br><span class="line">            h_dim=h_dim,</span><br><span class="line">            mlp_dim=mlp_dim,</span><br><span class="line">            num_layers=num_layers,</span><br><span class="line">            dropout=dropout</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        real_classifier_dims = [h_dim, mlp_dim, 1]</span><br><span class="line">        self.real_classifier = make_mlp(</span><br><span class="line">            real_classifier_dims,</span><br><span class="line">            activation=activation,</span><br><span class="line">            batch_norm=batch_norm,</span><br><span class="line">            dropout=dropout</span><br><span class="line">        )</span><br><span class="line">        if d_type == &#x27;global&#x27;:</span><br><span class="line">            mlp_pool_dims = [h_dim + embedding_dim, mlp_dim, h_dim]</span><br><span class="line">            self.pool_net = PoolHiddenNet(</span><br><span class="line">                embedding_dim=embedding_dim,</span><br><span class="line">                h_dim=h_dim,</span><br><span class="line">                mlp_dim=mlp_pool_dims,</span><br><span class="line">                bottleneck_dim=h_dim,</span><br><span class="line">                activation=activation,</span><br><span class="line">                batch_norm=batch_norm</span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">    def forward(self, traj, traj_rel, seq_start_end=None):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        Inputs:</span><br><span class="line">        - traj: Tensor of shape (obs_len + pred_len, batch, 2)</span><br><span class="line">        - traj_rel: Tensor of shape (obs_len + pred_len, batch, 2)</span><br><span class="line">        - seq_start_end: A list of tuples which delimit sequences within batch</span><br><span class="line">        Output:</span><br><span class="line">        - scores: Tensor of shape (batch,) with real/fake scores</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        final_h = self.encoder(traj_rel)</span><br><span class="line">        # Note: In case of &#x27;global&#x27; option we are using start_pos as opposed to</span><br><span class="line">        # end_pos. The intution being that hidden state has the whole</span><br><span class="line">        # trajectory and relative postion at the start when combined with</span><br><span class="line">        # trajectory information should help in discriminative behavior.</span><br><span class="line">        if self.d_type == &#x27;local&#x27;:</span><br><span class="line">            classifier_input = final_h.squeeze()</span><br><span class="line">        else:</span><br><span class="line">            classifier_input = self.pool_net(</span><br><span class="line">                final_h.squeeze(), seq_start_end, traj[0]</span><br><span class="line">            )</span><br><span class="line">        scores = self.real_classifier(classifier_input)</span><br><span class="line">        return scores</span><br></pre></td></tr></table></figure>





</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="mailto:undefined">Leon</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="http://example.com/2022/04/01/SGAN_2/">http://example.com/2022/04/01/SGAN_2/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Deep-Learning/">Deep Learning</a><a class="post-meta__tags" href="/tags/GAN/">GAN</a></div><div class="post_share"><div class="social-share" data-image="/img/blogtopimg/SGAN.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2022/04/17/SUN_HP/"><img class="prev-cover" src="/img/blogtopimg/think.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">Previous Post</div><div class="prev_info">孙振耀退休感言</div></div></a></div><div class="next-post pull-right"><a href="/2022/03/28/SGAN_1/"><img class="next-cover" src="/img/blogtopimg/SGAN.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">Next Post</div><div class="next_info">Social-GAN Open Source Code Analysis（1）</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>Related Articles</span></div><div class="relatedPosts-list"><div><a href="/2022/03/28/SGAN_1/" title="Social-GAN Open Source Code Analysis（1）"><img class="cover" src="/img/blogtopimg/SGAN.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-03-28</div><div class="title">Social-GAN Open Source Code Analysis（1）</div></div></a></div></div></div><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> Comment</span></div></div><div class="comment-wrap"><div><div class="vcomment" id="vcomment"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/me.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Leon</div><div class="author-info__description">MS in EE</div></div><div class="card-info-data is-center"><div class="card-info-data-item"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">10</div></a></div><div class="card-info-data-item"><a href="/tags/"><div class="headline">Tags</div><div class="length-num">7</div></a></div><div class="card-info-data-item"><a href="/categories/"><div class="headline">Categories</div><div class="length-num">0</div></a></div></div><a id="card-info-btn" href="mailto:jinsong.leon@gmail.com"><i class="fas fa-envelope"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/LeeXiaosong" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="https://www.zhihu.com/people/zhi-ai-mu-ni-hei-zhu" target="_blank" title="Zhihu"><i class="fa-brands fa-zhihu"></i></a><a class="social-icon" href="https://space.bilibili.com/22133996" target="_blank" title="Bilibili"><i class="fa-brands fa-bilibili"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>Announcement</span></div><div class="announcement_content">Keep the enthusiasm</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Catalog</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E9%83%A8%E5%88%86"><span class="toc-number">1.</span> <span class="toc-text">数据处理部分</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#models-py"><span class="toc-number">1.1.</span> <span class="toc-text">models.py</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#make-mlp"><span class="toc-number">1.1.1.</span> <span class="toc-text">make_mlp()</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#get-noise"><span class="toc-number">1.1.2.</span> <span class="toc-text">get_noise()</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Encoder-nn-Module"><span class="toc-number">1.1.3.</span> <span class="toc-text">Encoder(nn.Module)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#PoolHiddenNet-nn-Module"><span class="toc-number">1.1.4.</span> <span class="toc-text">PoolHiddenNet(nn.Module)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Decoder-nn-Module"><span class="toc-number">1.1.5.</span> <span class="toc-text">Decoder(nn.Module)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#TrajectoryGenerator-nn-Module"><span class="toc-number">1.1.6.</span> <span class="toc-text">TrajectoryGenerator(nn.Module)</span></a></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Post</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2023/03/15/GuangD/" title="A Trip to GuangZhou"><img src="/img/blogtopimg/GD6.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="A Trip to GuangZhou"/></a><div class="content"><a class="title" href="/2023/03/15/GuangD/" title="A Trip to GuangZhou">A Trip to GuangZhou</a><time datetime="2023-03-14T16:00:00.000Z" title="Created 2023-03-15 00:00:00">2023-03-15</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/07/31/ShenZ/" title="A Trip to Shenzhen"><img src="/img/blogtopimg/SZ4.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="A Trip to Shenzhen"/></a><div class="content"><a class="title" href="/2022/07/31/ShenZ/" title="A Trip to Shenzhen">A Trip to Shenzhen</a><time datetime="2022-07-30T16:00:00.000Z" title="Created 2022-07-31 00:00:00">2022-07-31</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/04/17/SUN_HP/" title="孙振耀退休感言"><img src="/img/blogtopimg/think.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="孙振耀退休感言"/></a><div class="content"><a class="title" href="/2022/04/17/SUN_HP/" title="孙振耀退休感言">孙振耀退休感言</a><time datetime="2022-04-16T16:00:00.000Z" title="Created 2022-04-17 00:00:00">2022-04-17</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/04/01/SGAN_2/" title="Social-GAN Open Source Code Analysis（二）"><img src="/img/blogtopimg/SGAN.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Social-GAN Open Source Code Analysis（二）"/></a><div class="content"><a class="title" href="/2022/04/01/SGAN_2/" title="Social-GAN Open Source Code Analysis（二）">Social-GAN Open Source Code Analysis（二）</a><time datetime="2022-03-31T16:00:00.000Z" title="Created 2022-04-01 00:00:00">2022-04-01</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/03/28/SGAN_1/" title="Social-GAN Open Source Code Analysis（1）"><img src="/img/blogtopimg/SGAN.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Social-GAN Open Source Code Analysis（1）"/></a><div class="content"><a class="title" href="/2022/03/28/SGAN_1/" title="Social-GAN Open Source Code Analysis（1）">Social-GAN Open Source Code Analysis（1）</a><time datetime="2022-03-27T16:00:00.000Z" title="Created 2022-03-28 00:00:00">2022-03-28</time></div></div></div></div></div></div></main><footer id="footer" style="background-image: url('/img/blogtopimg/SGAN.png')"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2023 By Leon</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a><br>
<i class="fa-solid fa-user-check"></i>
<a href="http://www.beian.miit.gov.cn/" target="_blank">渝ICP备2022003335号</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Read Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Toggle Between Light And Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle between single-column and double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="Setting"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table Of Contents"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="Scroll To Comments"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="Back To Top"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.js"></script><div class="js-pjax"><script>function loadValine () {
  function initValine () {
    const valine = new Valine(Object.assign({
      el: '#vcomment',
      appId: '',
      appKey: '',
      avatar: 'monsterid',
      serverURLs: '',
      emojiMaps: "",
      path: window.location.pathname,
      visitor: false
    }, null))
  }

  if (typeof Valine === 'function') initValine() 
  else getScript('https://cdn.jsdelivr.net/npm/valine/dist/Valine.min.js').then(initValine)
}

if ('Valine' === 'Valine' || !false) {
  if (false) btf.loadComment(document.getElementById('vcomment'),loadValine)
  else setTimeout(loadValine, 0)
} else {
  function loadOtherComment () {
    loadValine()
  }
}</script></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js"></script><script src="https://cdn.jsdelivr.net/gh/metowolf/MetingJS@1.2/dist/Meting.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>